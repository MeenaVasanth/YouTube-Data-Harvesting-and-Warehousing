{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='AIzaSyDxepCMFiHwr0ALaieUOeW1RPIZr3eCZNU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build(api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection details\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'youtube_final'  # The name of the PostgreSQL database\n",
    "username = 'postgres'      # PostgreSQL username\n",
    "password = 'malathi03'      # PostgreSQL password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL database using psycopg2\n",
    "eta = psycopg2.connect(host=host, port=port, database=database, user=username, password=password)\n",
    "cursor = eta.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve channel details using channel ID\n",
    "def get_channel_details(youtube, channel_id):\n",
    "    # Request channel details from YouTube API\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",  # Specify parts to retrieve\n",
    "        id=channel_id\n",
    "    )\n",
    "    \n",
    "    # Execute the API request\n",
    "    response = request.execute()\n",
    "\n",
    "    # Extract and store relevant channel information\n",
    "    for item in response['items']:\n",
    "        data = {\n",
    "            'channelName': item['snippet']['title'],  # Channel name\n",
    "            'channelId': item['id'],  # Channel ID\n",
    "            'subscribers': item['statistics']['subscriberCount'],  # Subscriber count\n",
    "            'views': item['statistics']['viewCount'],  # Total view count\n",
    "            'totalVideos': item['statistics']['videoCount'],  # Total video count\n",
    "            'playlistId': item['contentDetails']['relatedPlaylists']['uploads'],  # Uploads playlist ID\n",
    "            'channel_description': item['snippet']['description']  # Channel description\n",
    "        }\n",
    "    \n",
    "    # Return the collected data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function collects all playlists created by the channel using its channel ID\n",
    "def get_playlists_details(youtube, channel_id):\n",
    "    # Request playlist details from YouTube API\n",
    "    request = youtube.playlists().list(\n",
    "        part=\"snippet,contentDetails\",  # Specify parts to retrieve\n",
    "        channelId=channel_id,  # Channel ID\n",
    "        maxResults=25  # Max 25 playlists per request\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    All_data = []\n",
    "\n",
    "    # Loop through the playlists in the response\n",
    "    for item in response['items']:\n",
    "        data = {\n",
    "            'PlaylistId': item['id'],  # Playlist ID\n",
    "            'Title': item['snippet']['title'],  # Playlist title\n",
    "            'ChannelId': item['snippet']['channelId'],  # Channel ID\n",
    "            'ChannelName': item['snippet']['channelTitle'],  # Channel name\n",
    "            'PublishedAt': item['snippet']['publishedAt'],  # Playlist publish date\n",
    "            'VideoCount': item['contentDetails']['itemCount']  # Number of videos in the playlist\n",
    "        }\n",
    "        All_data.append(data)\n",
    "\n",
    "    # Get next page token to retrieve more playlists, if available\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    # Continue fetching playlists until no more pages\n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlists().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            channelId=channel_id,\n",
    "            maxResults=25\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Add new playlists to the data list\n",
    "        for item in response['items']:\n",
    "            data = {\n",
    "                'PlaylistId': item['id'],\n",
    "                'Title': item['snippet']['title'],\n",
    "                'ChannelId': item['snippet']['channelId'],\n",
    "                'ChannelName': item['snippet']['channelTitle'],\n",
    "                'PublishedAt': item['snippet']['publishedAt'],\n",
    "                'VideoCount': item['contentDetails']['itemCount']\n",
    "            }\n",
    "            All_data.append(data)\n",
    "\n",
    "        # Update next page token for further requests\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    return All_data  # Return all collected playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function retrieves all video IDs from a given playlist (usually the 'uploads' playlist for a channel)\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    # Initial request to get video IDs from the playlist\n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',  # Requesting content details (video IDs)\n",
    "        playlistId=playlist_id,  # Playlist ID (usually uploads playlist)\n",
    "        maxResults=50  # Maximum of 50 results per request\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "\n",
    "    # Initialize a list to store video IDs\n",
    "    video_ids = []\n",
    "\n",
    "    # Extract video IDs from the response and store them in the list\n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "\n",
    "    # Get next page token to check if there are more pages of video results\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "\n",
    "    # Loop to get video IDs from all pages until no more pages are left\n",
    "    while more_pages:\n",
    "        if next_page_token is None:  # If no more pages, exit the loop\n",
    "            more_pages = False\n",
    "        else:\n",
    "            # Request the next page of results\n",
    "            request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token  # Use the token to request the next page\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            # Extract and append video IDs from the new page\n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "\n",
    "            # Update the next page token for further requests\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    # Return the list of all video IDs collected from the playlist\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function retrieves details of a specific video using its video ID\n",
    "def get_video_info(youtube, video_id):\n",
    "\n",
    "    # Request to get details of the video from YouTube API\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet,contentDetails,statistics\",  # Specify parts to retrieve\n",
    "        id=video_id  # The unique video ID\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Initialize an empty dictionary to store video information\n",
    "    for video in response['items']:\n",
    "        stats_to_keep = {\n",
    "            'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt', 'channelId'],\n",
    "            'statistics': ['viewCount', 'likeCount', 'favoriteCount', 'commentCount'],\n",
    "            'contentDetails': ['duration', 'definition', 'caption']\n",
    "        }\n",
    "        \n",
    "        video_info = {}\n",
    "        video_info['video_id'] = video['id']  # Add video ID to the information\n",
    "\n",
    "        # Extract and store specific details from the video response\n",
    "        for key in stats_to_keep.keys():\n",
    "            for value in stats_to_keep[key]:\n",
    "                try:\n",
    "                    video_info[value] = video[key][value]  # Get the value if it exists\n",
    "                except KeyError:\n",
    "                    video_info[value] = None  # Set to None if the key is not found\n",
    "\n",
    "    # Return the collected video information\n",
    "    return video_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function retrieves comments for a given video using its video ID\n",
    "def get_comments_info(youtube, video_id):\n",
    "    all_comments = []  # List to store all comments\n",
    "\n",
    "    try:\n",
    "        # Request to get comments from the YouTube API\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet,replies\",  # Specify parts to retrieve\n",
    "            videoId=video_id  # The unique video ID\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Loop through the comments in the response\n",
    "        for item in response['items']:\n",
    "            data = {\n",
    "                'comment_id': item['snippet']['topLevelComment']['id'],  # Comment ID\n",
    "                'comment_txt': item['snippet']['topLevelComment']['snippet']['textOriginal'],  # Comment text\n",
    "                'videoId': item['snippet']['topLevelComment']['snippet']['videoId'],  # Video ID\n",
    "                'author_name': item['snippet']['topLevelComment']['snippet']['authorDisplayName'],  # Comment author's name\n",
    "                'published_at': item['snippet']['topLevelComment']['snippet']['publishedAt']  # Comment publish date\n",
    "            }\n",
    "            all_comments.append(data)  # Add the comment data to the list\n",
    "\n",
    "    except:\n",
    "        # Return an error message if comments could not be retrieved\n",
    "        return 'Could not get comments for video '  # Comments may be disabled for some videos\n",
    "\n",
    "    # Return the list of all comments retrieved\n",
    "    return all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_Details(channel_id):\n",
    "    \n",
    "    # Retrieve channel details and create a DataFrame\n",
    "    det = get_channel_details(youtube, channel_id)\n",
    "    channel_df = pd.DataFrame([det])  # Create a DataFrame for channel details\n",
    "    \n",
    "    # Retrieve all playlists for the channel and create a DataFrame\n",
    "    playlist = get_playlists_details(youtube, channel_id)\n",
    "    playlist_df = pd.DataFrame(playlist)  # Create a DataFrame for playlists\n",
    "    \n",
    "    # Get the playlist ID for the uploads playlist\n",
    "    Playlist = det.get('playlistId')\n",
    "    \n",
    "    # Retrieve video IDs from the playlist\n",
    "    videos = get_video_ids(youtube, Playlist)\n",
    "    \n",
    "    # Create an empty list to store video information\n",
    "    video_data = []\n",
    "    comment_data = []\n",
    "    \n",
    "    # For each video ID, retrieve video details and comments, and store them in lists\n",
    "    for i in videos:\n",
    "        v = get_video_info(youtube, i)\n",
    "        video_data.append(v)  # Collect video information for each video\n",
    "        \n",
    "        c = get_comments_info(youtube, i)\n",
    "        if c != 'Could not get comments for video ':\n",
    "            comment_data.extend(c)  # Collect comments for each video if available\n",
    "    \n",
    "    # Create DataFrames for videos and comments\n",
    "    video_df = pd.DataFrame(video_data)  # Create a DataFrame for videos\n",
    "    comment_df = pd.DataFrame(comment_data)  # Create a DataFrame for comments\n",
    "    \n",
    "    # Return all DataFrames\n",
    "    return channel_df, playlist_df, video_df, comment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the channel_Details function for 'Astronomic'\n",
    "channel_df, playlists_df, videos_df, comments_df = channel_Details('UCmXkiw-1x9ZhNOPz0X73tTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelName</th>\n",
       "      <th>channelId</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>totalVideos</th>\n",
       "      <th>playlistId</th>\n",
       "      <th>channel_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Astronomic</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>44500</td>\n",
       "      <td>4573764</td>\n",
       "      <td>89</td>\n",
       "      <td>UUmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>🤝 Patreon: https://www.patreon.com/astronomic\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelName                 channelId subscribers    views totalVideos  \\\n",
       "0  Astronomic  UCmXkiw-1x9ZhNOPz0X73tTA       44500  4573764          89   \n",
       "\n",
       "                 playlistId                                channel_description  \n",
       "0  UUmXkiw-1x9ZhNOPz0X73tTA  🤝 Patreon: https://www.patreon.com/astronomic\\...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlaylistId</th>\n",
       "      <th>Title</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>ChannelName</th>\n",
       "      <th>PublishedAt</th>\n",
       "      <th>VideoCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLUgKNEgezQonPSUNDhgzsbpyj08CZtC18</td>\n",
       "      <td>Astronomic.messier</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>2017-01-08T19:13:41Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLUgKNEgezQolWboh87MyDZeV2rACkcr1Z</td>\n",
       "      <td>Astronomic.what</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>2016-10-24T23:05:50Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLUgKNEgezQolYI7p5HKxF34kA1ODqUW5J</td>\n",
       "      <td>Astronomic.about</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>2016-02-17T12:01:11Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLUgKNEgezQolmAJ9jaorxGH93gCPw-t7i</td>\n",
       "      <td>Astronomic.quick</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>2015-08-04T17:24:00Z</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLUgKNEgezQompqqzB8rYjBE_2AcKOly34</td>\n",
       "      <td>Astronomic.edu</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>2013-08-13T18:32:09Z</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLUgKNEgezQonJA_UhXvBLJsKXyVo29SJL</td>\n",
       "      <td>Astronomic.10</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>2013-08-08T16:05:52Z</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PlaylistId               Title  \\\n",
       "0  PLUgKNEgezQonPSUNDhgzsbpyj08CZtC18  Astronomic.messier   \n",
       "1  PLUgKNEgezQolWboh87MyDZeV2rACkcr1Z     Astronomic.what   \n",
       "2  PLUgKNEgezQolYI7p5HKxF34kA1ODqUW5J    Astronomic.about   \n",
       "3  PLUgKNEgezQolmAJ9jaorxGH93gCPw-t7i    Astronomic.quick   \n",
       "4  PLUgKNEgezQompqqzB8rYjBE_2AcKOly34      Astronomic.edu   \n",
       "5  PLUgKNEgezQonJA_UhXvBLJsKXyVo29SJL       Astronomic.10   \n",
       "\n",
       "                  ChannelId ChannelName           PublishedAt  VideoCount  \n",
       "0  UCmXkiw-1x9ZhNOPz0X73tTA  Astronomic  2017-01-08T19:13:41Z           1  \n",
       "1  UCmXkiw-1x9ZhNOPz0X73tTA  Astronomic  2016-10-24T23:05:50Z           5  \n",
       "2  UCmXkiw-1x9ZhNOPz0X73tTA  Astronomic  2016-02-17T12:01:11Z           4  \n",
       "3  UCmXkiw-1x9ZhNOPz0X73tTA  Astronomic  2015-08-04T17:24:00Z           6  \n",
       "4  UCmXkiw-1x9ZhNOPz0X73tTA  Astronomic  2013-08-13T18:32:09Z          79  \n",
       "5  UCmXkiw-1x9ZhNOPz0X73tTA  Astronomic  2013-08-08T16:05:52Z           9  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlists_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>duration</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D4cF9jrseEE</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>A NEW Type of STAR?</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2021-01-17T18:30:23Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>3289</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>PT13M5S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wEf_2bnNdFo</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>The EXPANSION of the UNIVERSE!</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2020-12-01T18:00:12Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>22099</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>PT12M15S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEf2EQzKO1Q</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>The STRUCTURE of the UNIVERSE!</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2020-04-01T17:00:12Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>7931</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>PT10M38S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4--eeb_fwA</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>BLACK HOLES are EVERYWHERE!</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2019-05-05T20:00:00Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>5809</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>PT11M17S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-EoPw0_R1k</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>GALAXIES in the UNIVERSE!</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2018-02-28T18:00:00Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>5625</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>PT8M19S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4OdrV7gbyhU</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>What Is The Big Rip?</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2014-04-10T14:26:45Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>32538</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>PT5M56S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>qIdM8HyKwp4</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>How Hot Is Our Star?</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2014-03-28T02:14:41Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>2684</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PT6M48S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TP4loCNCzpM</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>Are There Planck Stars?</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2014-03-18T13:29:55Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>205583</td>\n",
       "      <td>4085</td>\n",
       "      <td>0</td>\n",
       "      <td>685</td>\n",
       "      <td>PT6M37S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>bFlS1mMpFRU</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>How Big Is The Universe?</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2014-02-06T21:38:58Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>1671</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PT5M21S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>AaeQon1ipHM</td>\n",
       "      <td>Astronomic</td>\n",
       "      <td>The Edge Of The Universe</td>\n",
       "      <td>🤝  Patreon: https://www.patreon.com/astronomic...</td>\n",
       "      <td>[space, cosmos, universe, nasa, science, astro...</td>\n",
       "      <td>2013-09-26T18:34:28Z</td>\n",
       "      <td>UCmXkiw-1x9ZhNOPz0X73tTA</td>\n",
       "      <td>4414</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>PT6M36S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id channelTitle                           title  \\\n",
       "0   D4cF9jrseEE   Astronomic             A NEW Type of STAR?   \n",
       "1   wEf_2bnNdFo   Astronomic  The EXPANSION of the UNIVERSE!   \n",
       "2   CEf2EQzKO1Q   Astronomic  The STRUCTURE of the UNIVERSE!   \n",
       "3   Q4--eeb_fwA   Astronomic     BLACK HOLES are EVERYWHERE!   \n",
       "4   4-EoPw0_R1k   Astronomic       GALAXIES in the UNIVERSE!   \n",
       "..          ...          ...                             ...   \n",
       "85  4OdrV7gbyhU   Astronomic            What Is The Big Rip?   \n",
       "86  qIdM8HyKwp4   Astronomic            How Hot Is Our Star?   \n",
       "87  TP4loCNCzpM   Astronomic         Are There Planck Stars?   \n",
       "88  bFlS1mMpFRU   Astronomic        How Big Is The Universe?   \n",
       "89  AaeQon1ipHM   Astronomic        The Edge Of The Universe   \n",
       "\n",
       "                                          description  \\\n",
       "0   🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "1   🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "2   🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "3   🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "4   🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "..                                                ...   \n",
       "85  🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "86  🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "87  🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "88  🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "89  🤝  Patreon: https://www.patreon.com/astronomic...   \n",
       "\n",
       "                                                 tags           publishedAt  \\\n",
       "0   [space, cosmos, universe, nasa, science, astro...  2021-01-17T18:30:23Z   \n",
       "1   [space, cosmos, universe, nasa, science, astro...  2020-12-01T18:00:12Z   \n",
       "2   [space, cosmos, universe, nasa, science, astro...  2020-04-01T17:00:12Z   \n",
       "3   [space, cosmos, universe, nasa, science, astro...  2019-05-05T20:00:00Z   \n",
       "4   [space, cosmos, universe, nasa, science, astro...  2018-02-28T18:00:00Z   \n",
       "..                                                ...                   ...   \n",
       "85  [space, cosmos, universe, nasa, science, astro...  2014-04-10T14:26:45Z   \n",
       "86  [space, cosmos, universe, nasa, science, astro...  2014-03-28T02:14:41Z   \n",
       "87  [space, cosmos, universe, nasa, science, astro...  2014-03-18T13:29:55Z   \n",
       "88  [space, cosmos, universe, nasa, science, astro...  2014-02-06T21:38:58Z   \n",
       "89  [space, cosmos, universe, nasa, science, astro...  2013-09-26T18:34:28Z   \n",
       "\n",
       "                   channelId viewCount likeCount favoriteCount commentCount  \\\n",
       "0   UCmXkiw-1x9ZhNOPz0X73tTA      3289       126             0           20   \n",
       "1   UCmXkiw-1x9ZhNOPz0X73tTA     22099       517             0           49   \n",
       "2   UCmXkiw-1x9ZhNOPz0X73tTA      7931       250             0           30   \n",
       "3   UCmXkiw-1x9ZhNOPz0X73tTA      5809       229             0           23   \n",
       "4   UCmXkiw-1x9ZhNOPz0X73tTA      5625       242             0           23   \n",
       "..                       ...       ...       ...           ...          ...   \n",
       "85  UCmXkiw-1x9ZhNOPz0X73tTA     32538       544             0           56   \n",
       "86  UCmXkiw-1x9ZhNOPz0X73tTA      2684        48             0            2   \n",
       "87  UCmXkiw-1x9ZhNOPz0X73tTA    205583      4085             0          685   \n",
       "88  UCmXkiw-1x9ZhNOPz0X73tTA      1671        53             0            4   \n",
       "89  UCmXkiw-1x9ZhNOPz0X73tTA      4414       101             0            6   \n",
       "\n",
       "    duration definition caption  \n",
       "0    PT13M5S         hd   false  \n",
       "1   PT12M15S         hd   false  \n",
       "2   PT10M38S         hd   false  \n",
       "3   PT11M17S         hd   false  \n",
       "4    PT8M19S         hd   false  \n",
       "..       ...        ...     ...  \n",
       "85   PT5M56S         hd   false  \n",
       "86   PT6M48S         hd   false  \n",
       "87   PT6M37S         hd   false  \n",
       "88   PT5M21S         hd   false  \n",
       "89   PT6M36S         hd   false  \n",
       "\n",
       "[90 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_txt</th>\n",
       "      <th>videoId</th>\n",
       "      <th>author_name</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgxWujymW0GFOIx1IZB4AaABAg</td>\n",
       "      <td>What is a Galaxy🤔?</td>\n",
       "      <td>D4cF9jrseEE</td>\n",
       "      <td>@home-edwindsor</td>\n",
       "      <td>2023-05-25T10:23:42Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugyi0uDMTWVv6zQ5DmZ4AaABAg</td>\n",
       "      <td>Keep it up 🙂🙂</td>\n",
       "      <td>D4cF9jrseEE</td>\n",
       "      <td>@cookingandvlogwithaqsaali3121</td>\n",
       "      <td>2022-06-16T15:37:31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgzAqqRNkv40gyHHfTB4AaABAg</td>\n",
       "      <td>I have a question that does not relate to this...</td>\n",
       "      <td>D4cF9jrseEE</td>\n",
       "      <td>@maplesblossoms2441</td>\n",
       "      <td>2022-01-07T16:11:23Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgxLqMC5DZSTWTTrdzF4AaABAg</td>\n",
       "      <td>Where are you now miss your videos</td>\n",
       "      <td>D4cF9jrseEE</td>\n",
       "      <td>@yeshdahiya2204</td>\n",
       "      <td>2021-10-07T02:11:22Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugw6MRQ2VekRgXKfIUt4AaABAg</td>\n",
       "      <td>Where are you guys :(</td>\n",
       "      <td>D4cF9jrseEE</td>\n",
       "      <td>@pawdaypay</td>\n",
       "      <td>2021-10-05T05:45:40Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>UgzcheYlZU-SCGEemct4AaABAg</td>\n",
       "      <td>that is tiokako@optusnet.com.au</td>\n",
       "      <td>AaeQon1ipHM</td>\n",
       "      <td>@juancarlossaavedra4505</td>\n",
       "      <td>2018-07-06T12:15:19Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>UgyzH9iqgVJROO56kqd4AaABAg</td>\n",
       "      <td>The Universe is finite in space and infinite i...</td>\n",
       "      <td>AaeQon1ipHM</td>\n",
       "      <td>@juancarlossaavedra4505</td>\n",
       "      <td>2018-07-06T12:14:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>UgzOHKqttscIh4Aykut4AaABAg</td>\n",
       "      <td>Not too bad kid, would be better if you were s...</td>\n",
       "      <td>AaeQon1ipHM</td>\n",
       "      <td>@KillsAll.</td>\n",
       "      <td>2018-03-11T03:50:45Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>UgxNWkadAm10d8GKEjN4AaABAg</td>\n",
       "      <td>I like the musical intro/background in this one</td>\n",
       "      <td>AaeQon1ipHM</td>\n",
       "      <td>@AlaskanBallistics</td>\n",
       "      <td>2017-12-07T06:43:35Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>UghXyxE8Fb_-o3gCoAEC</td>\n",
       "      <td>at 6 minutes.  needs rewording.  that number h...</td>\n",
       "      <td>AaeQon1ipHM</td>\n",
       "      <td>@userwl2850</td>\n",
       "      <td>2016-11-03T05:00:07Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1109 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      comment_id  \\\n",
       "0     UgxWujymW0GFOIx1IZB4AaABAg   \n",
       "1     Ugyi0uDMTWVv6zQ5DmZ4AaABAg   \n",
       "2     UgzAqqRNkv40gyHHfTB4AaABAg   \n",
       "3     UgxLqMC5DZSTWTTrdzF4AaABAg   \n",
       "4     Ugw6MRQ2VekRgXKfIUt4AaABAg   \n",
       "...                          ...   \n",
       "1104  UgzcheYlZU-SCGEemct4AaABAg   \n",
       "1105  UgyzH9iqgVJROO56kqd4AaABAg   \n",
       "1106  UgzOHKqttscIh4Aykut4AaABAg   \n",
       "1107  UgxNWkadAm10d8GKEjN4AaABAg   \n",
       "1108        UghXyxE8Fb_-o3gCoAEC   \n",
       "\n",
       "                                            comment_txt      videoId  \\\n",
       "0                                    What is a Galaxy🤔?  D4cF9jrseEE   \n",
       "1                                         Keep it up 🙂🙂  D4cF9jrseEE   \n",
       "2     I have a question that does not relate to this...  D4cF9jrseEE   \n",
       "3                    Where are you now miss your videos  D4cF9jrseEE   \n",
       "4                                 Where are you guys :(  D4cF9jrseEE   \n",
       "...                                                 ...          ...   \n",
       "1104                    that is tiokako@optusnet.com.au  AaeQon1ipHM   \n",
       "1105  The Universe is finite in space and infinite i...  AaeQon1ipHM   \n",
       "1106  Not too bad kid, would be better if you were s...  AaeQon1ipHM   \n",
       "1107    I like the musical intro/background in this one  AaeQon1ipHM   \n",
       "1108  at 6 minutes.  needs rewording.  that number h...  AaeQon1ipHM   \n",
       "\n",
       "                         author_name          published_at  \n",
       "0                    @home-edwindsor  2023-05-25T10:23:42Z  \n",
       "1     @cookingandvlogwithaqsaali3121  2022-06-16T15:37:31Z  \n",
       "2                @maplesblossoms2441  2022-01-07T16:11:23Z  \n",
       "3                    @yeshdahiya2204  2021-10-07T02:11:22Z  \n",
       "4                         @pawdaypay  2021-10-05T05:45:40Z  \n",
       "...                              ...                   ...  \n",
       "1104         @juancarlossaavedra4505  2018-07-06T12:15:19Z  \n",
       "1105         @juancarlossaavedra4505  2018-07-06T12:14:09Z  \n",
       "1106                      @KillsAll.  2018-03-11T03:50:45Z  \n",
       "1107              @AlaskanBallistics  2017-12-07T06:43:35Z  \n",
       "1108                     @userwl2850  2016-11-03T05:00:07Z  \n",
       "\n",
       "[1109 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the channels table in PostgreSQL\n",
    "def channels_table(channel_df): \n",
    "\n",
    "    try:\n",
    "        # Create the table if it does not exist\n",
    "        cursor.execute('''CREATE TABLE IF NOT EXISTS channels(\n",
    "                            channelName VARCHAR(50),\n",
    "                            channelId VARCHAR(80) PRIMARY KEY,\n",
    "                            subscribers BIGINT, \n",
    "                            views BIGINT,\n",
    "                            totalVideos INT,\n",
    "                            playlistId VARCHAR(80),\n",
    "                            channel_description TEXT\n",
    "                        )'''\n",
    "                       )\n",
    "        eta.commit()\n",
    "    except Exception as e:\n",
    "        eta.rollback()\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "    # Assuming `channel_df` is the DataFrame containing channel data\n",
    "    try:\n",
    "        for _, row in channel_df.iterrows():\n",
    "            # Define the insert query\n",
    "            insert_query = '''\n",
    "                INSERT INTO channels (channelName, channelId, subscribers, views, totalVideos, playlistId, channel_description)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (channelId) DO NOTHING  -- To avoid duplicates\n",
    "            '''\n",
    "            # Extract row values for insertion\n",
    "            values = (\n",
    "                row['channelName'],\n",
    "                row['channelId'],\n",
    "                row['subscribers'],\n",
    "                row['views'],\n",
    "                row['totalVideos'],\n",
    "                row['playlistId'],\n",
    "                row['channel_description']\n",
    "            )\n",
    "            try:\n",
    "                cursor.execute(insert_query, values)  # Insert the row into the table\n",
    "                eta.commit()  # Commit the transaction\n",
    "            except Exception as e:\n",
    "                eta.rollback()  # Rollback in case of an error\n",
    "                print(f\"Error inserting row {row['channelId']}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_table(channel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the playlists table in PostgreSQL\n",
    "def playlists_table(playlists_df): \n",
    "    try:\n",
    "        # Create the 'playlists' table if it doesn't already exist\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS playlists (\n",
    "                PlaylistId VARCHAR(100) PRIMARY KEY,\n",
    "                Title TEXT,\n",
    "                ChannelId VARCHAR(80),\n",
    "                ChannelName VARCHAR(50),\n",
    "                PublishedAt TIMESTAMP,\n",
    "                VideoCount INT\n",
    "            )\n",
    "        ''')\n",
    "        eta.commit()  # Commit the transaction to save the changes\n",
    "    except Exception as e:\n",
    "        eta.rollback()  # Rollback in case of an error\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "    # Assuming `playlists_df` is the DataFrame containing playlist data\n",
    "    try:\n",
    "        # Iterate over each row in the DataFrame\n",
    "        for _, row in playlists_df.iterrows():\n",
    "            # Define the SQL insert query\n",
    "            insert_query = '''\n",
    "                INSERT INTO playlists (\n",
    "                    PlaylistId, Title, ChannelId, ChannelName, PublishedAt, VideoCount\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (PlaylistId) DO NOTHING  -- Avoid duplicates\n",
    "            '''\n",
    "            # Prepare the values for the insert query\n",
    "            values = (\n",
    "                row['PlaylistId'],\n",
    "                row['Title'],\n",
    "                row['ChannelId'],\n",
    "                row['ChannelName'],\n",
    "                row['PublishedAt'],\n",
    "                row['VideoCount']\n",
    "            )\n",
    "            try:\n",
    "                # Execute the insert query\n",
    "                cursor.execute(insert_query, values)\n",
    "                eta.commit()  # Commit the transaction to save the changes\n",
    "            except Exception as e:\n",
    "                eta.rollback()  # Rollback in case of an error during insertion\n",
    "                print(f\"Error inserting row {row['PlaylistId']}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DataFrame: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_table(playlists_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the videos table in PostgreSQL\n",
    "def videos_table(videos_df):  \n",
    "    try:\n",
    "        # Create the 'videos' table if it doesn't already exist\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS videos (\n",
    "                video_id TEXT PRIMARY KEY, \n",
    "                channelTitle TEXT, \n",
    "                title TEXT, \n",
    "                description TEXT, \n",
    "                tags TEXT, \n",
    "                publishedAt TEXT, \n",
    "                viewCount TEXT, \n",
    "                likeCount TEXT,\n",
    "                favoriteCount TEXT, \n",
    "                commentCount TEXT, \n",
    "                duration TEXT, \n",
    "                definition TEXT, \n",
    "                caption TEXT, \n",
    "                channelId TEXT\n",
    "            )\n",
    "        ''')\n",
    "        eta.commit()  # Commit the transaction to save the changes\n",
    "    except Exception as e:\n",
    "        # Rollback in case of an error during table creation\n",
    "        eta.rollback()\n",
    "        print(f\"Error creating videos table: {e}\")\n",
    "\n",
    "    # Assuming `videos_df` is the DataFrame containing the videos data\n",
    "    try:\n",
    "        # Iterate over each row in the DataFrame\n",
    "        for _, row in videos_df.iterrows():\n",
    "            # Define the SQL insert query\n",
    "            insert_query = '''\n",
    "                INSERT INTO videos (\n",
    "                    video_id, channelTitle, title, description, tags, publishedAt, \n",
    "                    viewCount, likeCount, favoriteCount, commentCount, duration, \n",
    "                    definition, caption, channelId\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (video_id) DO NOTHING  -- Avoid duplicates\n",
    "            '''\n",
    "            # Prepare the values for the insert query\n",
    "            values = (\n",
    "                row['video_id'],\n",
    "                row['channelTitle'],\n",
    "                row['title'],\n",
    "                row['description'],\n",
    "                row['tags'],\n",
    "                row['publishedAt'],\n",
    "                row['viewCount'],\n",
    "                row['likeCount'],\n",
    "                row['favoriteCount'],\n",
    "                row['commentCount'],\n",
    "                row['duration'],\n",
    "                row['definition'],\n",
    "                row['caption'],\n",
    "                row['channelId']\n",
    "            )\n",
    "            try:\n",
    "                # Execute the insert query\n",
    "                cursor.execute(insert_query, values)\n",
    "                eta.commit()  # Commit the transaction to save the changes\n",
    "            except Exception as e:\n",
    "                # Rollback in case of an error during insertion\n",
    "                eta.rollback()\n",
    "                print(f\"Error inserting video {row['video_id']}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing videos DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_table(videos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the comments table in PostgreSQL\n",
    "def comments_table(comments_df): \n",
    "    try:\n",
    "        # Create the 'comments' table if it doesn't already exist\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS comments (\n",
    "                comment_id VARCHAR(100) PRIMARY KEY, \n",
    "                comment_txt TEXT, \n",
    "                videoId VARCHAR(80), \n",
    "                author_name VARCHAR(150), \n",
    "                published_at TIMESTAMP\n",
    "            )\n",
    "        ''')\n",
    "        eta.commit()  # Commit the transaction to save the changes\n",
    "    except Exception as e:\n",
    "        # Rollback in case of an error during table creation\n",
    "        eta.rollback()\n",
    "        print(f\"Error creating comments table: {e}\")\n",
    "\n",
    "    # Assuming `comments_df` is the DataFrame containing the comments data\n",
    "    try:\n",
    "        # Iterate over each row in the DataFrame\n",
    "        for _, row in comments_df.iterrows():\n",
    "            # Define the SQL insert query\n",
    "            insert_query = '''\n",
    "                INSERT INTO comments (\n",
    "                    comment_id, comment_txt, videoId, author_name, published_at\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (comment_id) DO NOTHING  -- Avoid duplicates\n",
    "            '''\n",
    "            # Prepare the values for the insert query\n",
    "            values = (\n",
    "                row['comment_id'],\n",
    "                row['comment_txt'],\n",
    "                row['videoId'],\n",
    "                row['author_name'],\n",
    "                row['published_at']\n",
    "            )\n",
    "            try:\n",
    "                # Execute the insert query\n",
    "                cursor.execute(insert_query, values)\n",
    "                eta.commit()  # Commit the transaction to save the changes\n",
    "            except Exception as e:\n",
    "                # Rollback in case of an error during insertion\n",
    "                eta.rollback()\n",
    "                print(f\"Error inserting comment {row['comment_id']}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing comments DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_table(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel ID: UCs9zUnxh-VQ5NL8Ewe45hqQ\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_channel_id(channel_name, api_key):\n",
    "    base_url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "    params = {\n",
    "        'part': 'snippet',\n",
    "        'q': channel_name,\n",
    "        'type': 'channel',\n",
    "        'key': api_key\n",
    "    }\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['items']:\n",
    "            channel_id = data['items'][0]['id']['channelId']\n",
    "            return channel_id\n",
    "        else:\n",
    "            return \"Channel not found.\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\"\n",
    "\n",
    "# Example usage\n",
    "api_key = 'AIzaSyDxepCMFiHwr0ALaieUOeW1RPIZr3eCZNU'\n",
    "channel_name = ''\n",
    "channel_id = get_channel_id(channel_name, api_key)\n",
    "print(f\"Channel ID: {channel_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
